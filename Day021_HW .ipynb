{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Day021_HW.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYueENiBtkkp",
        "colab_type": "text"
      },
      "source": [
        "## 『本次練習內容』\n",
        "#### 使用Xception backbone做 Trnasfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2BJ8JPJtkky",
        "colab_type": "text"
      },
      "source": [
        "## 『本次練習目的』\n",
        "  #### 了解如何使用Transfer Learning\n",
        "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsLCnT6ttkk1",
        "colab_type": "text"
      },
      "source": [
        "##### 可以自行嘗試多種架構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XtCSPB1tkk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense, GlobalAveragePooling2D \n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "input_tensor = Input(shape=(32, 32, 3))\n",
        "#include top 決定要不要加入 fully Connected Layer\n",
        "\n",
        "\n",
        "'''Xception 架構'''\n",
        "model=keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
        "                                           input_tensor=input_tensor,\n",
        "                                           pooling=None, classes=100)\n",
        "\n",
        "'''Resnet 50 架構'''\n",
        "#model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
        "                                    #input_tensor=input_tensor,\n",
        "                                    #pooling=None, classes=10)\n",
        "\n",
        "print('Model深度：', len(model.layers))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMACBwC7tkk_",
        "colab_type": "text"
      },
      "source": [
        "## 添加層數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axNj6pO3tklA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''可以參考Cifar10實作章節'''\n",
        "\n",
        "# from keras.layers import BatchNormalization\n",
        "\n",
        "x = model.output\n",
        "# x = BatchNormalization(axis=1, momentum=0.95, epsilon=0.05)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(activation=\"relu\", units=10)(x)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "\n",
        "predictions = Dense(activation=\"softmax\", units=10)(x)\n",
        "model = Model(inputs=model.input, outputs=predictions)\n",
        "print('Model深度：', len(model.layers))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "338zy2odtklF",
        "colab_type": "text"
      },
      "source": [
        "## 鎖定特定幾層不要更新權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOBcAUi6tklG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[100:]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgQ2bzP4tklJ",
        "colab_type": "text"
      },
      "source": [
        "## 準備 Cifar 10 資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxfrZFI3tklK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape) #(50000, 32, 32, 3)\n",
        "\n",
        "## Normalize Data\n",
        "def normalize(X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7)\n",
        "        return X_train, X_test\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_test = normalize(x_train, x_test) \n",
        "\n",
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
        "one_hot=OneHotEncoder()\n",
        "y_train=one_hot.fit_transform(y_train).toarray()\n",
        "y_test=one_hot.transform(y_test).toarray()\n",
        "\n",
        "\n",
        "## Training\n",
        "  # compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(x_train,y_train,batch_size=32,epochs=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikib3XUO9qPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "his = model.history\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "plt.title('Accurcy VS Loss with epochs')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "ax1.set_ylabel('(Loss)', color='black')\n",
        "ax1.set_ylim(0.5, 2.2)\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "ax1.plot(his.epoch,his.history[\"loss\"], label=\"loss\", color='black', alpha=1)\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('(Accurcy)', color='tab:blue')\n",
        "ax2.set_ylim(0.25, 0.8)\n",
        "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
        "ax2.plot(his.epoch, his.history[\"acc\"], label=\"Accurcy\", color='tab:blue', alpha=0.75)\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}